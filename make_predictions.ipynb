{"cells":[{"cell_type":"markdown","source":["# Make predictions from INPUT_FOLDER"],"metadata":{"id":"K60x_PmGqmpT"}},{"cell_type":"markdown","source":["Note that we assume your input data is stored as **.h5 files**, which contain both raw data (image) and its mask (label needed for metrics computations). The input data is in INPUT_FOLDER.\n","\n","**Remark** : if your data is in your GGDrive, you need to mount it first. All the code is provided.\n","\n","We return new h5 files, with \"raw\", \"label\" and \"pred\" as keys. The output data will be in a new folder OUTPUT_FOLDER.\n","\n","Enable GPU acceleration in \"Notebook parameters\" for faster predictions."],"metadata":{"id":"ajfOpLaarpPm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oWhdfePYHaG"},"outputs":[],"source":["INPUT_FOLDER = '/content/drive/MyDrive/6_aneurysm_segmentation/challenge_dataset/' # data to predict folder\n","OUTPUT_FOLDER = '/content/predictions/'\n","PRETRAINED_MODEL_PATH = '/content/drive/MyDrive/6_aneurysm_segmentation/3D_model_resnet18_Noneweights_100epochs_jaccard.best.hdf5'\n","COMPUTE_METRICS = True\n","\n","# Don't touch these - should be removed for final version\n","CROP = 64 # None or 64, None keeps the samples unchanged, 64 crops them to (64,64,64)\n","CENTER_CUBE_ONLY = True # False train on all data (split volume in 9 cubes), True train only on the middle (64,64,64) cube around the aneurysm = less data"]},{"cell_type":"markdown","source":["## Imports and Drive mount"],"metadata":{"id":"oYzQ_U5o7cDJ"}},{"cell_type":"code","source":["!pip install segmentation-models-3D --quiet"],"metadata":{"id":"Tr7FVLr16z6A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674215090016,"user_tz":-60,"elapsed":4951,"user":{"displayName":"Louis Stef","userId":"12702083290324095812"}},"outputId":"c866e927-f9eb-4537-b75e-b7be4638628b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting segmentation-models-3D\n","  Downloading segmentation_models_3D-1.0.4-py3-none-any.whl (33 kB)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-3D) (2.9.2)\n","Collecting classification-models-3D>=1.0.6\n","  Downloading classification_models_3D-1.0.6-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (1.21.6)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.14.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.19.6)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.12)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.51.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.29.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.6.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (21.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (4.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (57.4.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.3.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (15.0.6.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->segmentation-models-3D) (0.38.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.25.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.16.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.8.0->segmentation-models-3D) (3.0.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (5.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (6.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.2.2)\n","Installing collected packages: classification-models-3D, keras-applications, segmentation-models-3D\n","Successfully installed classification-models-3D-1.0.6 keras-applications-1.0.8 segmentation-models-3D-1.0.4\n"]}]},{"cell_type":"code","source":["# connect your drive to the session\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsW6j30t7LGH","executionInfo":{"status":"ok","timestamp":1674215111550,"user_tz":-60,"elapsed":17527,"user":{"displayName":"Louis Stef","userId":"12702083290324095812"}},"outputId":"05f0964a-6f64-48c9-f55b-bffcc5e270ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# import librairies\n","import numpy as np\n","import tensorflow as tf\n","import h5py\n","import os\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n","import segmentation_models_3D as sm\n","from tqdm import tqdm"],"metadata":{"id":"di-C5HeZ58P1","executionInfo":{"status":"ok","timestamp":1674215118089,"user_tz":-60,"elapsed":3986,"user":{"displayName":"Louis Stef","userId":"12702083290324095812"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2168b1c9-af64-416a-8044-e2c35d4c51de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `tf.keras` framework.\n"]}]},{"cell_type":"code","source":["def load_data_from(path_folder):\n","    \"\"\"\n","    Loads data from the folder and return 3 arrays (images, masks, filenames)\n","    \"\"\"\n","    # get file names\n","    file_names = os.listdir(path_folder)\n","    N = len(file_names)\n","    print(f'{N} samples in dataset.')\n","    print(file_names)\n","\n","    # open all .h5 files, split inputs and target masks, store all in np.arrays\n","    raw_data = []\n","    labels = []\n","    names = []\n","\n","    for file_name in tqdm(file_names):\n","        f = h5py.File(f'{path_folder}/{file_name}', 'r')\n","\n","        X, Y = np.array(f['raw']), np.array(f['label'])\n","\n","        if CROP is None:\n","            raw_data.append(X)\n","            labels.append(Y)\n","            names.append(file_name)\n","\n","        else:\n","            if CENTER_CUBE_ONLY: # only keep the center cube (over 9 candidates)\n","                X = X[:,CROP:2*CROP,CROP:2*CROP]\n","                Y = Y[:,CROP:2*CROP,CROP:2*CROP]\n","\n","                raw_data.append(X)\n","                labels.append(Y)\n","                names.append(file_name)\n","\n","            else: # keep all cubes = more data\n","                X_patches = patchify(X, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n","                X_patches_resh = np.reshape(X_patches, (-1, X_patches.shape[3], X_patches.shape[4], X_patches.shape[5]))\n","                Y_patches = patchify(Y, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n","                Y_patches_resh = np.reshape(Y_patches, (-1, Y_patches.shape[3], Y_patches.shape[4], Y_patches.shape[5]))\n","                raw_data.append(X_patches_resh)\n","                labels.append(Y_patches_resh)\n","                names.append(file_name)\n","\n","    # convert to arrays for patchify\n","    raw_data = np.array(raw_data)\n","    labels = np.array(labels)\n","\n","    if (CROP is not None) and (not CENTER_CUBE_ONLY): # only keep the center cube (over 9 candidates)\n","        raw_data = np.reshape(raw_data, (-1, raw_data.shape[2], raw_data.shape[3], raw_data.shape[4]))\n","        labels = np.reshape(labels, (-1, labels.shape[2], labels.shape[3], labels.shape[4]))\n","\n","    return raw_data, labels, names\n","\n","\n","def analytics(y_test, y_pred01):\n","    print(f'------ AFTER THRESHOLDING AT {THRESHOLD} ------')\n","    print('> sm.metrics.IOUScore :', sm.metrics.IOUScore()(y_test, y_pred01))\n","\n","    # precision_recall_fscore_support report\n","    precision, recall, fscore, support = precision_recall_fscore_support(y_test.flatten(), \n","                                                                      y_pred01.flatten()) \n","    print('> Precision :', precision[1])\n","    print('> Recall :', recall[1])\n","    print('> Fscore :', fscore[1])"],"metadata":{"id":"E43u3Av96n_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load pretrained model\n","print(f\"Reload from : {PRETRAINED_MODEL_PATH}\")\n","model = tf.keras.models.load_model(PRETRAINED_MODEL_PATH, compile=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7xOoRUm4Rk9","executionInfo":{"status":"ok","timestamp":1674215148679,"user_tz":-60,"elapsed":10325,"user":{"displayName":"Louis Stef","userId":"12702083290324095812"}},"outputId":"fda211d7-9877-447a-897f-d336a07c3316"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reload from : /content/drive/MyDrive/6_aneurysm_segmentation/3D_model_resnet18_Noneweights_100epochs_jaccard.best.hdf5\n"]}]},{"cell_type":"markdown","source":["The next cell runs the entire data loading, model loading, predictions and export process. Computing metrics is not mendatory but useful to evaluate the performance of the model."],"metadata":{"id":"duAU6G2G_-Ub"}},{"cell_type":"code","source":["# load data from INPUT_FOLDER\n","raw_data, labels, names = load_data_from(INPUT_FOLDER)\n","\n","# create output folder\n","os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n","\n","print(f'\\nCreated {OUTPUT_FOLDER}')\n","\n","X_to_predict = np.expand_dims(raw_data, axis=-1)\n","\n","y_pred = model.predict(X_to_predict, batch_size=2)\n","# convert to binary\n","THRESHOLD = 0.5\n","y_pred01 = (y_pred > THRESHOLD).squeeze()\n","\n","print('Predictions complete.')\n","\n","if COMPUTE_METRICS:\n","    # can take a few seconds, fill free to remove if you don't care about metrics\n","    analytics(np.array(labels, dtype='float32'), y_pred01)\n","\n","# convert to uint8 to match the initial format of the masks\n","y_pred01 = y_pred01.astype(np.uint8)\n","\n","\n","# save into OUTPUT_FOLDER\n","for i, filename in enumerate(names):\n","    raw = raw_data[i]\n","    label = labels[i]\n","    y_pred = y_pred01[i]\n","\n","    h5f = h5py.File(f'{OUTPUT_FOLDER}{filename}', 'w')\n","\n","    h5f.create_dataset('raw', data=raw)\n","    h5f.create_dataset('label', data=label)\n","    h5f.create_dataset('pred', data=y_pred)\n","\n","    h5f.close()\n","\n","print('\\nExport complete.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zi5NH_latZOb","executionInfo":{"status":"ok","timestamp":1674215307562,"user_tz":-60,"elapsed":156570,"user":{"displayName":"Louis Stef","userId":"12702083290324095812"}},"outputId":"36343471-ada1-446e-ae49-101ffdf421bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["103 samples in dataset.\n","['scan_1.h5', 'scan_3.h5', 'scan_2.h5', 'scan_4.h5', 'scan_5.h5', 'scan_6.h5', 'scan_7.h5', 'scan_8.h5', 'scan_9.h5', 'scan_11.h5', 'scan_10.h5', 'scan_13.h5', 'scan_14.h5', 'scan_12.h5', 'scan_16.h5', 'scan_18.h5', 'scan_17.h5', 'scan_15.h5', 'scan_19.h5', 'scan_20.h5', 'scan_21.h5', 'scan_23.h5', 'scan_22.h5', 'scan_24.h5', 'scan_27.h5', 'scan_26.h5', 'scan_28.h5', 'scan_25.h5', 'scan_31.h5', 'scan_29.h5', 'scan_30.h5', 'scan_34.h5', 'scan_35.h5', 'scan_33.h5', 'scan_32.h5', 'scan_38.h5', 'scan_37.h5', 'scan_36.h5', 'scan_40.h5', 'scan_41.h5', 'scan_39.h5', 'scan_43.h5', 'scan_42.h5', 'scan_44.h5', 'scan_48.h5', 'scan_46.h5', 'scan_45.h5', 'scan_47.h5', 'scan_51.h5', 'scan_49.h5', 'scan_50.h5', 'scan_55.h5', 'scan_54.h5', 'scan_53.h5', 'scan_52.h5', 'scan_57.h5', 'scan_58.h5', 'scan_56.h5', 'scan_60.h5', 'scan_61.h5', 'scan_59.h5', 'scan_64.h5', 'scan_62.h5', 'scan_63.h5', 'scan_65.h5', 'scan_66.h5', 'scan_67.h5', 'scan_70.h5', 'scan_69.h5', 'scan_68.h5', 'scan_74.h5', 'scan_73.h5', 'scan_71.h5', 'scan_72.h5', 'scan_77.h5', 'scan_76.h5', 'scan_75.h5', 'scan_78.h5', 'scan_79.h5', 'scan_81.h5', 'scan_80.h5', 'scan_82.h5', 'scan_83.h5', 'scan_86.h5', 'scan_85.h5', 'scan_84.h5', 'scan_87.h5', 'scan_89.h5', 'scan_88.h5', 'scan_90.h5', 'scan_92.h5', 'scan_91.h5', 'scan_96.h5', 'scan_94.h5', 'scan_95.h5', 'scan_93.h5', 'scan_98.h5', 'scan_97.h5', 'scan_100.h5', 'scan_99.h5', 'scan_102.h5', 'scan_103.h5', 'scan_101.h5']\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 103/103 [00:11<00:00,  8.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Created /content/predictions/\n","52/52 [==============================] - 128s 2s/step\n","Predictions complete.\n","------ AFTER THRESHOLDING AT 0.5 ------\n","> sm.metrics.IOUScore : tf.Tensor(0.53295004, shape=(), dtype=float32)\n","> Precision : 0.6465867888760054\n","> Recall : 0.7520121585752205\n","> Fscore : 0.6953260299458679\n","\n","Export complete.\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"lm2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"ef3dd97f72c7de1b6cf4acbe3ecc775b9ffc9904b79c9969b32a495aa0a05a59"}}},"nbformat":4,"nbformat_minor":0}