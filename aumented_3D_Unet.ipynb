{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13663,"status":"ok","timestamp":1674059701016,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"-GgiwGIhyFD7","outputId":"86236a8f-84dc-4153-b638-6ea609f49bc9"},"outputs":[],"source":["# Install all dependencies for sgementation-models-3D library.\n","# We will use this library to call 3D unet.\n","# Alternative, you can define your own Unet, if you have skills!\n","!pip install classification-models-3D\n","!pip install efficientnet-3D\n","!pip install segmentation-models-3D\n","\n","# Use patchify to break large volumes into smaller for training \n","#and also to put patches back together after prediction.\n","!pip install patchify"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1674059701018,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"YYBoXnNWD8-G","outputId":"a7925eee-ac47-4ee8-f4c7-4a061b0378a2"},"outputs":[],"source":["import os\n","import random\n","import logging\n","import h5py\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n","\n","# funky librairies for segmentation\n","import segmentation_models_3D as sm\n","from patchify import patchify, unpatchify\n","\n","print('All librairies sucessfully imported.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32512,"status":"ok","timestamp":1674059733522,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"Gz38BGA4DeRk","outputId":"d5ac8dc7-49de-47e8-f191-ac25faf41dcc"},"outputs":[],"source":["# import data\n","PATH_COLAB = '/content/drive/MyDrive/6_aneurysm_segmentation/challenge_dataset.zip'\n","PATH_DEVICE = './challenge_dataset/'\n","\n","try:\n","    from google.colab import drive\n","    logging.info('Working on Colab.')\n","    \n","    # connect your drive to the session\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/MyDrive/6_aneurysm_segmentation/\n","\n","    # unzip data into the colab session\n","    ! unzip $PATH_COLAB -d /content\n","    logging.info('Data unziped in your Drive.')\n","\n","    %cd ../../..\n","\n","except:\n","    logging.info('Working on your device.')\n","    \n","    data_exists = os.path.exists(PATH_DEVICE)\n","    \n","    if data_exists:\n","        logging.info(f\"Dataset found on device at : '{PATH_DEVICE}.'\") \n","    else:\n","        raise FileNotFoundError(f\"Data folder not found at '{PATH_DEVICE}'\")"]},{"cell_type":"markdown","metadata":{"id":"X-IV7SfcsNrL"},"source":["# Get data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1674059733523,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"snVgFwtKsNBX"},"outputs":[],"source":["PATH_DATASET='./challenge_dataset/'\n","TEST_SIZE = 0.2 # % of test samples from the full dataset\n","VAL_SPLIT = 0.2 # % of training samples kept for the validation metrics\n","CROP = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3159,"status":"ok","timestamp":1674059736635,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"0u_AyZ73sksB","outputId":"90c6cd5e-cd0c-4b9f-e501-5fa8c5af62a0"},"outputs":[],"source":["# get file names\n","file_names = os.listdir(PATH_DATASET)\n","N = len(file_names)\n","print(f'{N} samples in dataset.')\n","\n","# open all .h5 files, split inputs and target masks, store all in np.arrays\n","raw_data = []\n","labels = []\n","names = []\n","\n","for file_name in tqdm(file_names):\n","    f = h5py.File(f'{PATH_DATASET}/{file_name}', 'r')\n","\n","    X, Y = np.array(f['raw']), np.array(f['label'])\n","\n","    X = X[:,CROP:2*CROP,CROP:2*CROP]\n","    Y = Y[:,CROP:2*CROP,CROP:2*CROP]\n","\n","    raw_data.append(X)\n","    labels.append(Y)\n","    names.append(file_name)\n","\n","    # TO KEEP FOR LATER - USEFUL TO ADD FREE SAMPLES BY CROPPING\n","    # X_patches = patchify(X, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n","    # X_patches_resh = np.reshape(X_patches, (-1, X_patches.shape[3], X_patches.shape[4], X_patches.shape[5]))\n","    # Y_patches = patchify(Y, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n","    # Y_patches_resh = np.reshape(Y_patches, (-1, Y_patches.shape[3], Y_patches.shape[4], Y_patches.shape[5]))\n","    # raw_data.append(X_patches_resh)\n","    # labels.append(Y_patches_resh)\n","    # names.append(file_name)\n","\n","# convert to arrays for patchify\n","raw_data = np.array(raw_data)\n","labels = np.array(labels)\n","\n","# raw_data = np.reshape(raw_data, (-1, raw_data.shape[2], raw_data.shape[3], raw_data.shape[4]))\n","# labels = np.reshape(labels, (-1, labels.shape[2], labels.shape[3], labels.shape[4]))\n","\n","raw_data = np.stack((raw_data,) * 3, axis=-1)\n","labels = np.expand_dims(labels, axis=4)\n","\n","# check shapes\n","print(raw_data.shape)\n","print(labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1674059736636,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"WQPWex6Ouoeq","outputId":"db9dee99-8bed-4364-cdca-1b939442bc81"},"outputs":[],"source":["SCAN_ID = 45\n","DEPTH = 32\n","\n","fig, ax = plt.subplots(1, 2)\n","ax[0].imshow(raw_data[SCAN_ID,:,:,DEPTH,0])\n","ax[1].imshow(labels[SCAN_ID,:,:,DEPTH,0]) # last 0 to get a 2D image\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1674059741685,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"Cmns6kSV1aHP","outputId":"b10cc144-6674-451c-c207-ade4c5f5b194"},"outputs":[],"source":["# split train and test data\n","X_train, X_test, y_train, y_test = train_test_split(raw_data, labels, test_size=TEST_SIZE)\n","\n","# train_test_split returns lists, we want arrays for easier calls\n","X_train = np.array(X_train)\n","X_test = np.array(X_test)\n","y_train = np.array(y_train, dtype='float32')\n","y_test = np.array(y_test, dtype='float32')\n","\n","# check shapes\n","print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"syLWn-vUr4uR"},"source":["# Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674059996096,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"Ldet_7qar6MS"},"outputs":[],"source":["import os\n","import numpy as np\n","import h5py\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","class AugmentedGenerator:\n","    '''\n","    Example Usage:\n","    >>> augmented_generator = AugmentedGenerator()\n","    >>> train_generator = augmented_generator.train_generator\n","    >>> validation_generator = augmented_generator.validation_generator\n","    >>> model.fit(train_generator, validation_data=validation_generator, epochs=10)\n","    '''\n","    def __init__(self, path='./challenge_dataset/', validation_split=0.2, batch_size=16, seed=1):\n","        self.path = path\n","        self.validation_split = validation_split\n","        self.batch_size = batch_size\n","        self.seed = seed\n","        self.raw = None\n","        self.labels = None\n","        self._load_data()\n","        self.train_generator = self._get_train_generator()\n","        self.validation_generator = self._get_validation_generator()\n","    \n","    def _load_data(self):\n","        '''\n","        Loads the data from the .h5 files, might be better to use a generator here as well.\n","        '''\n","        data_exists = os.path.exists(self.path)\n","\n","        if not data_exists:\n","            raise FileNotFoundError(f\"Data folder not found at '{self.path}'\")\n","        else:\n","            l_raw = []\n","            l_label = []\n","            for i in range(103): # might be better to make it cleaner\n","                f = h5py.File(self.path + f'scan_{i+1}.h5', 'r')\n","                l_raw.append(f['raw'])\n","                l_label.append(f['label'])\n","            self.raw, self.labels = np.array(l_raw), np.array(l_label)\n","\n","    def _get_train_generator(self):\n","        '''\n","        Returns a generator for the training data with data augmentation.\n","        '''\n","        data_gen_params = dict(\n","            validation_split=self.validation_split,\n","            rotation_range=90,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            shear_range=0.2,\n","            zoom_range=0.2,\n","            horizontal_flip=True,\n","            fill_mode='nearest',\n","            data_format='channels_first'\n","        )\n","        data_gen = ImageDataGenerator(**data_gen_params)\n","        \n","        return data_gen.flow(self.raw, self.labels, batch_size=self.batch_size, subset='training', seed=self.seed)\n","\n","\n","    def _get_validation_generator(self):\n","        '''\n","        Returns a generator for the validation data : no data augmentation.\n","        '''\n","        data_gen = ImageDataGenerator(\n","            validation_split=self.validation_split,\n","            data_format='channels_first')\n","        return data_gen.flow(self.raw, self.labels, batch_size=self.batch_size, subset='validation', seed=self.seed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12518,"status":"ok","timestamp":1674060014418,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"rse9ZBa5sPho","outputId":"6cad858b-515f-43f5-df05-b8df4b5068fe"},"outputs":[],"source":["# get file names in the folder\n","PATH_DATASET = 'challenge_dataset'\n","\n","file_names = os.listdir(PATH_DATASET)\n","N = len(file_names)\n","\n","VAL_SPLIT = 0.4\n","BATCH_SIZE = 6\n","\n","generator = AugmentedGenerator(validation_split=VAL_SPLIT, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1674060014418,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"7u5dmwWysiQf"},"outputs":[],"source":["train_data_pipeline, val_data_pipeline = generator.train_generator, generator.validation_generator"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":303,"status":"ok","timestamp":1674060183760,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"qKfDb7bAsl_H"},"outputs":[],"source":["def crop(generator, crop_size = CROP, preprocess = lambda x:x, channels = 3):\n","    while True:\n","        x, y = next(generator)\n","\n","        crop_x, crop_y = np.zeros((len(x), crop_size, crop_size, crop_size)), np.zeros((len(x), crop_size, crop_size, crop_size))\n","\n","        for i in range(len(x)):\n","            aneurysm_indexes = np.nonzero(y[i])\n","\n","            z_min, z_max = aneurysm_indexes[0].min(), aneurysm_indexes[0].max()\n","            x_min, x_max = aneurysm_indexes[1].min(), aneurysm_indexes[1].max()\n","            y_min, y_max = aneurysm_indexes[2].min(), aneurysm_indexes[2].max()\n","\n","            #print(z_min, z_max, x_min, x_max, y_min, y_max)\n","\n","            z_init = np.random.randint(max(0, z_max - crop_size), max(max(0, z_max - crop_size) + 1, min(z_min + 1, x.shape[1] - crop_size)))\n","            y_init = np.random.randint(max(0, y_max - crop_size), max(max(0, y_max - crop_size) + 1, min(y_min + 1, x.shape[3] - crop_size)))\n","            x_init = np.random.randint(max(0, x_max - crop_size), max(max(0, x_max - crop_size) + 1, min(x_min + 1, x.shape[2] - crop_size)))\n","\n","            #print(x.shape)\n","\n","            crop_x[i] = x[i,z_init: z_init + crop_size, x_init: x_init + crop_size, y_init : y_init + crop_size]\n","            crop_y[i] = y[i,z_init: z_init + crop_size, x_init: x_init + crop_size, y_init : y_init + crop_size]\n","\n","\n","        \n","\n","        \n","        yield(preprocess(np.stack((crop_x,)*channels, axis=-1)), crop_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674060184685,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"NIJ6erYHsmnC"},"outputs":[],"source":["crop_train = crop(train_data_pipeline)\n","crop_val = crop(val_data_pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1192,"status":"ok","timestamp":1674060187444,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"SUuIu_jdwS-k","outputId":"d8e1a6ed-6b8a-4692-a2e7-898f80f17ca3"},"outputs":[],"source":["next(crop_train)[0].shape"]},{"cell_type":"markdown","metadata":{"id":"Gs3sOxQ_w61o"},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":423,"status":"ok","timestamp":1674060190872,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"6DdxfpVyxkgz"},"outputs":[],"source":["# Loss Function and coefficients to be used during training:\n","def custom_iou(smooth=1e-6):\n","    \"\"\"\n","    Returns a IoU function, with a custom smoothing parameter.\n","    Such a double function is needed because loss function in Keras are expected\n","    to take only two parameters. Therefore, smooth couldn't be a parameter.\n","    May be removed in future commits beacuse seems finally useless.\n","    \"\"\"\n","    def IoULoss(targets, inputs):\n","        \"\"\"\n","        Returns the intersection over union (IoU) of the two inputs masks.\n","        \"\"\"\n","        inputs = tf.cast(inputs, tf.float32)\n","        targets = tf.cast(targets, tf.float32)\n","        # flatten label and prediction tensors\n","        inputs = K.flatten(inputs)\n","        targets = K.flatten(targets)\n","\n","        intersection = K.sum(targets * inputs)\n","        total = K.sum(targets) + K.sum(inputs)\n","        union = total - intersection\n","        \n","        IoU = (intersection + smooth) / (union + smooth)\n","        return 1 - IoU\n","\n","    return IoULoss"]},{"cell_type":"markdown","metadata":{"id":"bkVlkakCxyVn"},"source":["Backbones: ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext50', 'seresnext101', 'senet154', 'resnext50', 'resnext101', 'vgg16', 'vgg19', 'densenet121', 'densenet169', 'densenet201', 'inceptionresnetv2', 'inceptionv3', 'mobilenet', 'mobilenetv2', 'efficientnetb0', 'efficientnetb1', 'efficientnetb2', 'efficientnetb3', 'efficientnetb4', 'efficientnetb5', 'efficientnetb6', 'efficientnetb7']\n","\n","So far, what worked best for our dataset (IOU_test = 43%) is:\n","```\n","BACKBONE = 'resnet50'\n","LOSS_TYPE = 'jaccard'\n","BATCH_SIZE = 8\n","LR = 1e-4\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1674060191721,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"rBFvmGbwFSzA","outputId":"39d5ed10-321d-41a1-84bb-2fd2290dce27"},"outputs":[],"source":["# MODEL PARAMETERS\n","encoder_weights = 'imagenet' # Try 'imagenet' or None (random initialization)\n","BACKBONE = 'resnet50'  # Try vgg16, efficientnetb7, inceptionv3, resnet50\n","activation = 'sigmoid' # final layer activation function, sigmoid for binary\n","patch_size = 64 # cube side length\n","n_classes = 1 # num channels output, here binary segmentation so 1\n","channels = 3 # num channels input, need 3 because backbones are trained on RGB\n","LOSS_TYPE = 'jaccard' # check dict 'losses' down below\n","\n","# TRAINING PARAMETERS\n","LR = 1e-4 # starting learning rate\n","EPOCHS = 100\n","BATCH_SIZE = 12\n","\n","MODEL_NAME = f'./3D_model_{BACKBONE}_{encoder_weights}weights_{EPOCHS}epochs_{LOSS_TYPE}'\n","print(MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1674061188912,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"FCgohzgAxvZL"},"outputs":[],"source":["# Define optimizer\n","optim = tf.keras.optimizers.Adam(LR)\n","\n","# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n","# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n","dice_loss = sm.losses.DiceLoss() \n","jaccard_loss = sm.losses.JaccardLoss()\n","focal_loss = sm.losses.BinaryFocalLoss()\n","\n","losses = {'dice': dice_loss,\n","          'jaccard': jaccard_loss,\n","          'custom_jaccard': custom_iou(),\n","          'focal_loss': focal_loss,\n","          'dice_focal': dice_loss + (1 * focal_loss), \n","          'jaccard_focal': jaccard_loss + (1 * focal_loss), \n","          }\n","\n","total_loss = losses.get(LOSS_TYPE)\n","assert total_loss is not None, ('Loss not defined. Check your spelling of LOSS_TYPE or the dict losses.')\n","\n","# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n","# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n","metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674061189731,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"8SHby8ZSA7di"},"outputs":[],"source":["# add callbacks to monitor training \n","weight_path = \"{}_weights.best.hdf5\".format(MODEL_NAME)\n","\n","checkpoint = ModelCheckpoint(weight_path, \n","                             monitor='val_loss', \n","                             verbose=1, \n","                             save_best_only=True, \n","                             mode='min', \n","                             save_weights_only=True)\n","\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', \n","                                   factor=0.5, \n","                                   patience=4, \n","                                   verbose=1, \n","                                   mode='auto', \n","                                   min_delta=0.0001, \n","                                   cooldown=5, \n","                                   min_lr=1e-6)\n","\n","early = EarlyStopping(monitor=\"val_loss\", \n","                      mode=\"min\", \n","                      patience=12) \n","\n","callbacks_list = [checkpoint, \n","                  early, \n","                  reduceLROnPlat]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1674061190546,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"1AsL9m0Vylhv"},"outputs":[],"source":["# Preprocess input data - otherwise you end up with garbage resutls \n","# and potentially model that does not converge.\n","preprocess_input = sm.get_preprocessing(BACKBONE)\n","\n","X_train_prep = preprocess_input(X_train)\n","X_test_prep = preprocess_input(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2849,"status":"ok","timestamp":1674061194263,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"c4BU9vulysVv"},"outputs":[],"source":["# Define the model. Here we use Unet but we can also use other model architectures from the library.\n","model = sm.Unet(BACKBONE, classes=n_classes, \n","                input_shape=(patch_size, patch_size, patch_size, channels), \n","                encoder_weights=encoder_weights,\n","                activation=activation)\n","\n","model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n","# print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZVRRSvRsyIm","outputId":"e1613cb1-0394-4cf4-b20d-b7d2c7208f28"},"outputs":[],"source":["val_steps = int(N * VAL_SPLIT) // BATCH_SIZE\n","train_steps = int(N * (1 - VAL_SPLIT)) // BATCH_SIZE\n","\n","crop_train = crop(train_data_pipeline, preprocess=preprocess_input)\n","crop_val = crop(val_data_pipeline, preprocess=preprocess_input)\n","\n","history = model.fit(crop_train, \n","            steps_per_epoch=train_steps,\n","            epochs=400,\n","            validation_data=crop_val,\n","            validation_steps=val_steps,\n","            callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1674061183891,"user":{"displayName":"Théophile Le Clerc","userId":"01984603867520953562"},"user_tz":-60},"id":"EatzsLOJyyQb"},"outputs":[],"source":["# Fit the model\n","#history = model.fit(X_train_prep, \n","#                    batch_size=BATCH_SIZE, \n","#                    y_train,\n","#                    epochs=EPOCHS,\n","#                    verbose=1,\n","#                    validation_split=VAL_SPLIT,\n","#                    callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JT542kX4Aec"},"outputs":[],"source":["# plot the training and validation IoU and loss at each epoch\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'y', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","acc = history.history['iou_score']\n","val_acc = history.history['val_iou_score']\n","\n","plt.plot(epochs, acc, 'y', label='Training IOU')\n","plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n","plt.title('Training and validation IOU')\n","plt.xlabel('Epochs')\n","plt.ylabel('IOU')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9iHYhf7cMuft"},"source":["# Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4FCXAqL4N2J"},"outputs":[],"source":["# Load the pretrained model for testing and predictions. \n","# you need a model instance before loading weights\n","print(f\"Reload weights from : {MODEL_NAME}_weights.best.hdf5\")\n","model.load_weights(f\"{MODEL_NAME}_weights.best.hdf5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC_3XiLr4UUA"},"outputs":[],"source":["# Predict on the test data\n","y_pred = model.predict(X_test_prep)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esjwzfGgMsYh"},"outputs":[],"source":["THRESHOLD = 0.5\n","\n","y_pred01 = (y_pred > THRESHOLD).astype(int) # float => boolean => binary (0/1)\n","\n","print(f'------ AFTER THRESHOLDING AT {THRESHOLD} ------')\n","print('> sm.metrics.IOUScore :', sm.metrics.IOUScore()(y_test, y_pred01).numpy())\n","print('> Custom IoU :', 1 - custom_iou()(y_test, y_pred01).numpy()) # to check my custom function, it was a loss so 1 - loss\n","\n","# precision_recall_fscore_support report\n","precision, recall, fscore, support = precision_recall_fscore_support(y_test.flatten(), \n","                                                                  y_pred01.flatten()) \n","print('> Precision :', precision[1])\n","print('> Recall :', recall[1])\n","print('> Fscore :', fscore[1])\n","\n","# Confusion matrix\n","cm = confusion_matrix(y_test.flatten(), \n","                      y_pred01.flatten())\n","print('\\nConfusion matrix :\\n', cm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmFcNaaV4ikj"},"outputs":[],"source":["# Test some random images\n","\n","# pick a random test scan and its ground truth mask\n","test_img_number = random.randint(0, len(X_test)-1)\n","print(f'I choose test image n° {test_img_number} ...')\n","\n","test_img = X_test[test_img_number]\n","ground_truth = y_test[test_img_number]\n","\n","# process input image before prediction\n","test_img_input = np.expand_dims(test_img, 0)\n","test_img_input1 = preprocess_input(test_img_input)\n","\n","# prediction\n","test_pred = model.predict(test_img_input1)\n","test_pred = test_pred.squeeze()\n","\n","# thresholding + reshaping\n","print(test_pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhxAdxYk4yxj"},"outputs":[],"source":["# Plot individual slices from test predictions for verification\n","SLICE_MIN, SLICE_MAX = 25, 45\n","\n","for slice in range(SLICE_MIN, SLICE_MAX+1):\n","    plt.figure(figsize=(12, 8))\n","    plt.subplot(231)\n","    plt.title(f'Testing Image {slice}')\n","    plt.imshow(test_img[slice,:,:,0], cmap='gray')\n","    plt.subplot(232)\n","    plt.title(f'Testing Label {slice}')\n","    plt.imshow(ground_truth[slice,:,:,0])\n","    plt.subplot(233)\n","    plt.title(f'Prediction on test image {slice}')\n","    plt.imshow(test_pred[slice,:,:])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oWhdfePYHaG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/19tchoubou/anevrisme_segmentation/blob/main/Unet3D_baseline_stef.ipynb","timestamp":1674058374668}]},"gpuClass":"standard","kernelspec":{"display_name":"lm2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"ef3dd97f72c7de1b6cf4acbe3ecc775b9ffc9904b79c9969b32a495aa0a05a59"}}},"nbformat":4,"nbformat_minor":0}
