{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# funky librairies for segmentation\n",
    "import segmentation_models_3D as sm\n",
    "from patchify import patchify, unpatchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET='./challenge_dataset/'\n",
    "CENTER_CUBE_ONLY = False # False train on all data (split volume in 9 cubes), True train only on a (64,64,64) cube around the aneurysm = less data\n",
    "TEST_SIZE = 0.2 # % of test samples from the full dataset\n",
    "VAL_SPLIT = 0.2 # % of training samples kept for the validation metrics\n",
    "CROP = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file names\n",
    "file_names = os.listdir(PATH_DATASET)\n",
    "N = len(file_names)\n",
    "print(f'{N} samples in dataset.')\n",
    "\n",
    "# open all .h5 files, split inputs and target masks, store all in np.arrays\n",
    "raw_data = []\n",
    "labels = []\n",
    "names = []\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    f = h5py.File(f'{PATH_DATASET}/{file_name}', 'r')\n",
    "\n",
    "    X, Y = np.array(f['raw']), np.array(f['label'])\n",
    "\n",
    "    if CENTER_CUBE_ONLY: # only keep the center cube (over 9 candidates)\n",
    "        X = X[:,CROP:2*CROP,CROP:2*CROP]\n",
    "        Y = Y[:,CROP:2*CROP,CROP:2*CROP]\n",
    "\n",
    "        raw_data.append(X)\n",
    "        labels.append(Y)\n",
    "        names.append(file_name)\n",
    "\n",
    "    else: # keep all = more data\n",
    "        X_patches = patchify(X, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n",
    "        X_patches_resh = np.reshape(X_patches, (-1, X_patches.shape[3], X_patches.shape[4], X_patches.shape[5]))\n",
    "        Y_patches = patchify(Y, (64, 64, 64), step=64)  # Step=64 for 64 patches means no overlap\n",
    "        Y_patches_resh = np.reshape(Y_patches, (-1, Y_patches.shape[3], Y_patches.shape[4], Y_patches.shape[5]))\n",
    "        raw_data.append(X_patches_resh)\n",
    "        labels.append(Y_patches_resh)\n",
    "        names.append(file_name)\n",
    "\n",
    "# convert to arrays for patchify\n",
    "raw_data = np.array(raw_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "if not CENTER_CUBE_ONLY: # only keep the center cube (over 9 candidates)\n",
    "    raw_data = np.reshape(raw_data, (-1, raw_data.shape[2], raw_data.shape[3], raw_data.shape[4]))\n",
    "    labels = np.reshape(labels, (-1, labels.shape[2], labels.shape[3], labels.shape[4]))\n",
    "\n",
    "# check shapes\n",
    "print(raw_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 4\n",
    "slice = 32\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(raw_data[ID, slice])\n",
    "plt.subplot(122)\n",
    "plt.imshow(labels[ID, slice])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence import DataGenerator\n",
    "from volumentations import *\n",
    "\n",
    "def get_augmentation(patch_size):\n",
    "    return Compose([\n",
    "        Rotate((-15, 15), (0, 0), (0, 0), p=0.5),\n",
    "        # RandomCropFromBorders(crop_value=0.1, p=0.5),\n",
    "        ElasticTransform((0, 0.25), interpolation=2, p=0.1),\n",
    "        Resize(patch_size, interpolation=1, resize_type=0, always_apply=True, p=0.5),\n",
    "        Flip(0, p=0.5),\n",
    "        Flip(1, p=0.5),\n",
    "        Flip(2, p=0.5),\n",
    "        RandomRotate90((1, 2), p=0.5),\n",
    "        # GaussianNoise(var_limit=(0, 5), p=0.2),\n",
    "        # RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    ], p=0.8)\n",
    "\n",
    "aug = get_augmentation((64, 64, 64))\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "x = raw_data\n",
    "y = labels\n",
    "\n",
    "gen = DataGenerator(raw_data=x, \n",
    "                    labels=y, \n",
    "                    augmentator=aug,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    input_shape=(64, 64, 64),\n",
    "                    shuffle=False\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_y in gen:\n",
    "    print(batch_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = 32\n",
    "id = 4\n",
    "\n",
    "batch_x, batch_y = gen[0]\n",
    "\n",
    "img = raw_data[id,slice]\n",
    "lbl = labels[id,slice]\n",
    "\n",
    "aug_img = batch_x[id,slice]\n",
    "aug_lbl = batch_y[id,slice]\n",
    "\n",
    "print('batch shape', batch_x.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img)\n",
    "plt.subplot(222)\n",
    "plt.imshow(lbl)\n",
    "plt.subplot(223)\n",
    "plt.imshow(aug_img)\n",
    "plt.subplot(224)\n",
    "plt.imshow(aug_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augmented_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmented_generator import AugmentedPairGenerator, CustomImageDataGenerator\n",
    "\n",
    "data_gen_params = dict(\n",
    "            validation_split=VAL_SPLIT,\n",
    "            rotation_range=180,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            data_format='channels_first'\n",
    "            # shear_range=45, # in degrees counterclockwise\n",
    "        )\n",
    "\n",
    "augmented_gen = AugmentedPairGenerator(x=raw_data,\n",
    "                                       y=labels,\n",
    "                                       data_gen_params=data_gen_params,\n",
    "                                       batch_size=16,\n",
    "                                       seed=0)\n",
    "\n",
    "pair_gen = augmented_gen.pair_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(pair_gen)\n",
    "x, y = batch\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x[0,32])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that the masks are modified with the transformations as the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = 32\n",
    "\n",
    "count = 0\n",
    "for i, (img, lbl) in enumerate(pair_gen):\n",
    "    for x, y in zip(img, lbl):\n",
    "        if 1 in np.unique(y[slice]):\n",
    "            plt.figure()\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(x[slice])\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(y[slice])\n",
    "            plt.show()\n",
    "            \n",
    "            # count += 1\n",
    "            \n",
    "        if count == 20:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_params = dict(\n",
    "            validation_split=VAL_SPLIT,\n",
    "            rotation_range=180,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            data_format='channels_first'\n",
    "            # shear_range=45, # in degrees counterclockwise\n",
    "        )\n",
    "\n",
    "data_gen = CustomImageDataGenerator(**data_gen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = data_gen.flow(x=raw_data,\n",
    "                               #   y=labels,\n",
    "                               batch_size=16,\n",
    "                               seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data_generator)\n",
    "# x = batch\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(x[0,32])\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumentations-3D\n",
    "\n",
    "https://github.com/ZFTurbo/volumentations#volumentations-3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install volumentations-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from volumentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation(patch_size):\n",
    "    return Compose([\n",
    "        Rotate((-15, 15), (0, 0), (0, 0), p=0.5),\n",
    "        RandomCropFromBorders(crop_value=0.1, p=0.5),\n",
    "        ElasticTransform((0, 0.25), interpolation=2, p=0.1),\n",
    "        Resize(patch_size, interpolation=1, resize_type=0, always_apply=True, p=1.0),\n",
    "        Flip(0, p=0.5),\n",
    "        Flip(1, p=0.5),\n",
    "        Flip(2, p=0.5),\n",
    "        RandomRotate90((1, 2), p=0.5),\n",
    "        GaussianNoise(var_limit=(0, 5), p=0.2),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    ], p=1.0)\n",
    "\n",
    "aug = get_augmentation((64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.random.randint(0, 255, size=(128, 256, 256), dtype=np.uint8)\n",
    "# lbl = np.random.randint(0, 1, size=(128, 256, 256), dtype=np.uint8)\n",
    "img = raw_data[4]\n",
    "lbl = labels[4]\n",
    "\n",
    "# with mask\n",
    "data = {'image': img, 'mask': lbl}\n",
    "aug_data = aug(**data)\n",
    "aug_img, aug_lbl = aug_data['image'], aug_data['mask']\n",
    "\n",
    "# without mask\n",
    "# data = {'image': img}\n",
    "# aug_data = aug(**data)\n",
    "# img = aug_data['image']\n",
    "\n",
    "slice = 32\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img[slice])\n",
    "plt.subplot(222)\n",
    "plt.imshow(lbl[slice])\n",
    "plt.subplot(223)\n",
    "plt.imshow(aug_img[slice])\n",
    "plt.subplot(224)\n",
    "plt.imshow(aug_lbl[slice])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(raw_data[4])\n",
    "\n",
    "# Define custom data augmentation function\n",
    "def data_augmentation(image):\n",
    "    # perform data augmentation\n",
    "    \n",
    "    aug = get_augmentation((64, 64, 64))\n",
    "    \n",
    "    # with mask\n",
    "    data = {'image': img}\n",
    "    aug_data = aug(**data)\n",
    "    augmented_image = aug_data['image']\n",
    "        \n",
    "    return augmented_image\n",
    "\n",
    "# Apply data augmentation to dataset\n",
    "dataset = dataset.map(data_augmentation)\n",
    "\n",
    "# Batch, shuffle and repeat the dataset\n",
    "dataset = dataset.batch(32).shuffle(buffer_size=1024).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef3dd97f72c7de1b6cf4acbe3ecc775b9ffc9904b79c9969b32a495aa0a05a59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
