{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "edge_weight = torch.tensor([1, 1, 0, 0])\n",
    "train_mask = torch.tensor([True, False, False])\n",
    "data = Data(x=x, edge_index=edge_index, edge_weight=edge_weight, train_mask=train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that maps (64, 192, 192) -> [0, 2359295]\n",
    "shape = (48, 48, 48)\n",
    "def volume_to_graph(i,j,k, shape=shape):\n",
    "    z, y, x = shape\n",
    "    return k + y * j + y * x * i\n",
    "\n",
    "def graph_to_volume(idx, shape=shape):\n",
    "    z, y, x = shape\n",
    "    i, r = divmod(idx, y * x)\n",
    "    j, k = divmod(r, y)\n",
    "    return (i,j,k)\n",
    "\n",
    "def correct_edge(i,j,k, shape=shape):\n",
    "    z, y, x = shape\n",
    "    return (0 <= i < z) and (0 <= j < y) and (0 <= k < x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_to_graph(0, 1, 2, shape=shape)\n",
    "graph_to_volume(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_to_volume(volume_to_graph(21, 1, 47, shape=shape), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -1\n",
    "for i in range(shape[0]):\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            assert graph_to_volume(volume_to_graph(i,j,k, shape=shape), shape=shape) == (i,j,k)\n",
    "            assert correct_edge(i,j,k, shape=shape)\n",
    "print(\"done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 / 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "sigma = 0.04\n",
    "edge_index0 = []\n",
    "edge_index1 = []\n",
    "edge_weight = []\n",
    "for i in range(shape[0]):\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            new_edges = [(i, j+1, k), (i, j, k+1), (i, j-1, k), (i, j, k-1), \n",
    "                            #(i, j+2, k), (i, j, k+2), (i, j-2, k), (i, j, k-2), \n",
    "                            #(i, j+1, k+1), (i, j-1, k+1), (i, j-1, k+1), (i, j-1, k-1), \n",
    "                            (i-1, j, k), (i+1, j, k)]\n",
    "            new_edges_weight = 4*[exp(-(7/192)**2 / (2 *sigma**2))] + 2*[exp(-(3/64)**2 / (2 *sigma**2))] # + 4*[exp(-(0.3**2 + 0.3**2) / (2 *sigma**2))] + 2*[exp(-0.7**2 / (2 *sigma**2))]\n",
    "            \n",
    "            current_v = volume_to_graph(i,j,k)\n",
    "            for coord, weight in zip(new_edges, new_edges_weight):\n",
    "                if correct_edge(*coord):\n",
    "                    edge_index0.append(current_v)\n",
    "                    edge_index1.append(volume_to_graph(*coord))\n",
    "                    edge_weight.append(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape[0] * shape[1] * shape[2] * 14 - 2*shape[1]*shape[2] - 2*(shape[1] + shape[2])*shape[0] - (2*(shape[1] + shape[2])*4 - 4)*shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_index0) == len(edge_index1) == len(edge_weight)== shape[0] * shape[1] * shape[2] * 14 - 2*shape[1]*shape[2] - 2*(shape[1] + shape[2])*shape[0] - (2*(shape[1] + shape[2])*4 - 4)*shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([edge_index0,\n",
    "                           edge_index1], dtype=torch.long)\n",
    "edge_weight = torch.tensor(edge_weight, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crop(x,y,crop_size=shape[0]):\n",
    "\n",
    "    crop_x, crop_y = np.zeros((crop_size, crop_size, crop_size)), np.zeros((crop_size, crop_size, crop_size))\n",
    "\n",
    "    aneurysm_indexes = np.nonzero(y)\n",
    "\n",
    "    z_min, z_max = aneurysm_indexes[0].min(), aneurysm_indexes[0].max()\n",
    "    x_min, x_max = aneurysm_indexes[1].min(), aneurysm_indexes[1].max()\n",
    "    y_min, y_max = aneurysm_indexes[2].min(), aneurysm_indexes[2].max()\n",
    "\n",
    "    #print(z_min, z_max, x_min, x_max, y_min, y_max)\n",
    "\n",
    "    z_init = (x.shape[0] - crop_size) // 2 #np.random.randint(max(0, z_max - crop_size), max(max(0, z_max - crop_size) + 1, min(z_min + 1, x.shape[0] - crop_size)))\n",
    "    y_init = (x.shape[2] - crop_size) // 2 #np.random.randint(max(0, y_max - crop_size), max(max(0, y_max - crop_size) + 1, min(y_min + 1, x.shape[2] - crop_size)))\n",
    "    x_init = (x.shape[1] - crop_size) // 2 #np.random.randint(max(0, x_max - crop_size), max(max(0, x_max - crop_size) + 1, min(x_min + 1, x.shape[1] - crop_size)))\n",
    "\n",
    "    #print(x.shape)\n",
    "\n",
    "    crop_x = x[z_init: z_init + crop_size, x_init: x_init + crop_size, y_init : y_init + crop_size]\n",
    "    crop_y = y[z_init: z_init + crop_size, x_init: x_init + crop_size, y_init : y_init + crop_size]\n",
    "\n",
    "    return crop_x, crop_y\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def BFS(mat, edges, processed, i):\n",
    " \n",
    "    # créer une file d'attente vide et mettre en file d'attente le nœud source\n",
    "    q = deque()\n",
    "    q.append(i)\n",
    " \n",
    "    # marquer le nœud source comme traité\n",
    "    processed[i] = 1\n",
    " \n",
    "    # Boucle # jusqu'à ce que la Queue soit vide\n",
    "    while q:\n",
    "        # retirer de la file d'attente le nœud frontal et le traiter\n",
    "        x = q.popleft()\n",
    " \n",
    "        # vérifie les huit mouvements possibles à partir de la cellule actuelle\n",
    "        # et mettre en file d'attente chaque mouvement valide\n",
    "        valid_edges = torch.argwhere(edges[0] == x)\n",
    "        for edge in valid_edges:\n",
    "            y = edges[1, edge]\n",
    "            # sauter si l'emplacement est invalide, ou déjà traité, ou a de l'eau\n",
    "            if processed[y] == 0 and mat[y] == True:\n",
    "                # sauter si l'emplacement est invalide, ou il est déjà\n",
    "                # traité ou composé d'eau\n",
    "                processed[y] = 1\n",
    "                q.append(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def make_one_hot(input, num_classes):\n",
    "    \"\"\"Convert class index tensor to one hot encoding tensor.\n",
    "    Args:\n",
    "         input: A tensor of shape [N, 1, *]\n",
    "         num_classes: An int of number of class\n",
    "    Returns:\n",
    "        A tensor of shape [N, num_classes, *]\n",
    "    \"\"\"\n",
    "    shape = np.array(input.shape)\n",
    "    shape[1] = num_classes\n",
    "    shape = tuple(shape)\n",
    "    result = torch.zeros(shape)\n",
    "    result = result.scatter_(1, input.cpu(), 1)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# get file names in the folder\n",
    "PATH_DATASET = 'challenge_dataset'\n",
    "\n",
    "file_names = os.listdir(PATH_DATASET)\n",
    "N = len(file_names)\n",
    "\n",
    "# ## Raw Data and labels\n",
    "\n",
    "dataset = []\n",
    "names = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    f = h5py.File(f'{PATH_DATASET}/{file_name}', 'r')\n",
    "\n",
    "    X, Y = np.array(f['raw']), np.array(f['label'])\n",
    "\n",
    "    X, Y = crop(X, Y, 48)\n",
    "    \n",
    "    flat_X = X.flatten().reshape((-1, 1)).astype(float)\n",
    "    x = torch.from_numpy(flat_X) / 255.\n",
    "\n",
    "    y = torch.from_numpy(Y.astype(int))\n",
    "\n",
    "    aneurysms = np.nonzero(Y)\n",
    "    if len(aneurysms[0]) == 0:\n",
    "        print(\"no label for \", file_name)\n",
    "        continue\n",
    "    i, j, k = np.mean(aneurysms[0]), np.mean(aneurysms[1]), np.mean(aneurysms[2])\n",
    "    i, j, k = int(i), int(j), int(k)\n",
    "    if Y[i,j,k] != 1:\n",
    "        print(\"surely 2 aneurysms for \", file_name)\n",
    "        continue\n",
    "\n",
    "    central_aneurysm = np.zeros_like(Y.flatten(), dtype=int)\n",
    "    \n",
    "    BFS(Y.flatten(), edge_index, central_aneurysm, volume_to_graph(i,j,k))\n",
    "\n",
    "    central_aneurysm = torch.from_numpy(central_aneurysm)\n",
    "\n",
    "    aneurysms = np.nonzero(central_aneurysm.numpy().reshape(Y.shape))\n",
    "\n",
    "    i, j, k = np.mean(aneurysms[0]), np.mean(aneurysms[1]), np.mean(aneurysms[2])\n",
    "    i, j, k = int(i), int(j), int(k)\n",
    "    if Y[i,j,k] != 1:\n",
    "        print(\"euh bug \", file_name)\n",
    "        continue\n",
    "\n",
    "    height_erosion = (y.roll(1,0) + y + y.roll(-1,0) == 3)\n",
    "    x_erosion = (torch.roll(y, 1 ,1) + y + torch.roll(y, shifts=(-1), dims=(1)) == 3)\n",
    "    y_erosion = (y.roll(1,2) + y + y.roll(-1,2) == 3)\n",
    "    erosion_mask = torch.logical_and(torch.logical_and(height_erosion, x_erosion), y_erosion).flatten().reshape((-1, 1)).float()\n",
    "    \n",
    "    center_mask = torch.zeros_like(erosion_mask, dtype=float) - 1.\n",
    "    center_mask[volume_to_graph(i,j,k)] = 1\n",
    "    y = y.flatten()\n",
    "    if erosion_mask.sum() == 0:\n",
    "        print(\"empty interior for \", file_name)\n",
    "        continue\n",
    "    train_mask = torch.tensor(flat_X.size * [True], dtype=bool)\n",
    "    new_edge_weight = edge_weight.clone()\n",
    "    \n",
    "    for i, (v1, v2) in enumerate(zip(edge_index[0], edge_index[1])):\n",
    "        new_edge_weight[i] = edge_weight[i] * (1 - abs(x[v1] - x[v2]))\n",
    "    \n",
    "    data = Data(x=torch.column_stack([x, center_mask]), edge_index=edge_index, edge_weight=new_edge_weight[new_edge_weight >= edge_weight / 2.], train_mask=train_mask, y=make_one_hot(central_aneurysm.reshape(-1,1), num_classes=2))\n",
    "    dataset.append(data)\n",
    "    names.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    print(data)\n",
    "    if data.has_isolated_nodes():\n",
    "        print(\"ouah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(2, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=6)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def make_one_hot(input, num_classes):\n",
    "    \"\"\"Convert class index tensor to one hot encoding tensor.\n",
    "    Args:\n",
    "         input: A tensor of shape [N, 1, *]\n",
    "         num_classes: An int of number of class\n",
    "    Returns:\n",
    "        A tensor of shape [N, num_classes, *]\n",
    "    \"\"\"\n",
    "    shape = np.array(input.shape)\n",
    "    shape[1] = num_classes\n",
    "    shape = tuple(shape)\n",
    "    result = torch.zeros(shape)\n",
    "    result = result.scatter_(1, input.cpu(), 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss of binary class\n",
    "    Args:\n",
    "        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n",
    "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n",
    "        predict: A tensor of shape [N, *]\n",
    "        target: A tensor of shape same with predict\n",
    "        reduction: Reduction method to apply, return mean over batch if 'mean',\n",
    "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    Raise:\n",
    "        Exception if unexpected reduction\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1, p=2, reduction='mean'):\n",
    "        super(BinaryDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
    "        predict = predict.contiguous().view(predict.shape[0], -1)\n",
    "        target = target.contiguous().view(target.shape[0], -1)\n",
    "\n",
    "        num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n",
    "        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n",
    "\n",
    "        loss = 1 - num / den\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception('Unexpected reduction {}'.format(self.reduction))\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss, need one hot encode input\n",
    "    Args:\n",
    "        weight: An array of shape [num_classes,]\n",
    "        ignore_index: class index to ignore\n",
    "        predict: A tensor of shape [N, C, *]\n",
    "        target: A tensor of same shape with predict\n",
    "        other args pass to BinaryDiceLoss\n",
    "    Return:\n",
    "        same as BinaryDiceLoss\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None, ignore_index=None, **kwargs):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.weight = weight\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        assert predict.shape == target.shape, 'predict & target shape do not match'\n",
    "        dice = BinaryDiceLoss(**self.kwargs)\n",
    "        total_loss = 0\n",
    "        predict = F.softmax(predict, dim=1)\n",
    "\n",
    "        for i in range(target.shape[1]):\n",
    "            if i != self.ignore_index:\n",
    "                dice_loss = dice(predict[:, i], target[:, i])\n",
    "                if self.weight is not None:\n",
    "                    assert self.weight.shape[0] == target.shape[1], \\\n",
    "                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n",
    "                    dice_loss *= self.weight[i]\n",
    "                total_loss += dice_loss\n",
    "\n",
    "        return total_loss/target.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = GCN(hidden_channels=4).float()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = DiceLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def train(loader):\n",
    "      for batch in loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "            out = model(batch.x.float(), batch.edge_index, batch.edge_weight)  # Perform a single forward pass.\n",
    "            loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test(data):\n",
    "      model.eval()\n",
    "      out = model(data.x.float(), data.edge_index, data.edge_weight)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred == data.y.argmax(dim=1)  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(len(data.x))  # Derive ratio of correct predictions.\n",
    "      return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 8\n",
    "num_batch = 4\n",
    "loader = DataLoader(dataset[:batchsize*num_batch], batch_size=batchsize, shuffle=True)\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    loss = train(loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[80]\n",
    "\n",
    "model.eval()\n",
    "out = model(data.x.float(), data.edge_index, data.edge_weight)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "true_class = data.y.argmax(dim=1)\n",
    "test_correct = pred == true_class  # Check against ground-truth labels.\n",
    "\n",
    "true_label = (true_class == 1)\n",
    "\n",
    "test_acc = int(test_correct.sum()) / int(len(data.x))  # Derive ratio of correct predictions.\n",
    "\n",
    "recall = int(test_correct[true_label].sum()) / int(len(data.x[true_label]))\n",
    "\n",
    "precision = int(test_correct[np.logical_and(true_label, pred == 1)].sum()) / int(len(pred == 1))\n",
    "\n",
    "print(len(pred == 1), len(data.x[true_label]))\n",
    "\n",
    "print(test_acc, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pred = pred.reshape(shape)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.voxels(np.where(pred > 0.5, 1, 0), color='r', edgecolor='k', alpha=0.5)\n",
    "ax.voxels(np.where(data.y.argmax(dim=1).reshape(shape) > 0.5, 1, 0) , color='g', edgecolor='k', alpha=0.5)\n",
    "ax.set(xlabel='channel', ylabel='width', zlabel='height')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
